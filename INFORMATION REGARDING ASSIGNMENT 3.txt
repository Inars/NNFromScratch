Dear Students,

A few comments related to ASSIGNMNET 3.

1)      REGARDING the use of a VALIDATION set: this is a separate portion of the training data which IS NOT USED DIRECTLY in 
training but is used for TESTING the trained model DURIN THE TRAINING PROCESS, so as to stop training in the optimal moment. 
You train the network on a train data and after every N iterations (for instance N=10 or 20) you test the accuracy of the 
(partly) trained model on the validation data set (which is not used directly for training). You stop the training procedure 
when you notice that the accuracy on the validation set drops â€“ this is the sigh of OVERFITTING which is a very undesired effect 
of too long training.

 

For more info see e.g. WIKIPEDIA:

https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets

2)      REGARDING THE ERROR MEASURE: you should use accuracy: in the case of discrete data you simply compare the resulting class 
with the correct one and if they are the same the classification of that sample is correct. In the case of continuous data you use 
mean square error.

 

3)      REGARDING THE PLOT OF THE TRAINING PROGRESS: you are supposed to plot the accuracy during training process. The plot can be 
drawn off-line, i.e. after the training proces is completed. In the plot you need to present the accuracy on both TRAINING and 
VALIDATION sets. After training you need to report the final accuracy on the TEST set and be able to analyse the results in the 
context of TRAINING and VALIDATION errors.

 

4)      REGARDING THE NETWORK MODEL: you use MLP with dynamically defined architecture: the number of hidden layers and their sizes 
HAVE TO BE DEFINED BY THE USER DYNAMICALLY / ON-LINE / DURING PROGRAM EXECUTION --- they SHOULD NOT BE HARDCODED IN THE PROGRAM (!). 
The size of the input layer is determined by the data representation (number of decriptive features). The size of the output layer 
equals to the number of classes in the dataset.